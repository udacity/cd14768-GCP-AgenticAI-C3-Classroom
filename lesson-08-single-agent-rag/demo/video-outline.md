# cd14768 - Lesson 8 - demo

Implementing Single-Agent RAG with ADK and Vertex AI Search

- In this demo, we'll be creating an agent that provides information from 
  various financial documents - in this case, the past few quarterly and 
  annual reports from Google.
  - We want to ground our results on these documents - not on any other 
    data the LLM may hallucinate or have access to.
  - Retrieval Augmented Generation (RAG) is the general solution to doing so
    - Use a tool to identify potential additional sources that are relevant 
      to the prompt and retrieve them
    - Add them to the prompt sent to the LLM
    - The LLM uses this additional context to help ground its answer
  - There are many possible ways to implement this.
    - Example: Grounding with Google Search
    - Example: Traditional database retrieval
    - Very common one is to use vector databases with similarity search to 
      retrieve "chunks" of a document that are more semantically similar to 
      the question.
    - Vertex AI Search provides one way that combines vector 
      searching and traditional indexing to locate results
- Setup
    - Create a Google Cloud Storage bucket and upload the sample PDF files from
      the `docs` folder
    - Vertex AI Search
    - Create a new App of type "Custom Search (general)"
    - Create a Data Store, selecting Cloud Storage as the source and
      "Unstructured documents"
    - Link the Data Store to the App
    - Note the "App ID" (this will be the `DATASTORE_ENGINE_ID`)
    - Note the "Location" (e.g., global)
    - Create or update `.env` with `DATASTORE_PROJECT_ID`, `DATASTORE_LOCATION`,
      and `DATASTORE_ENGINE_ID`
    - Run `gcloud auth application-default login` to authenticate
- [agent.py] Show `root_agent` configuration
    - This is the high-level entry point
    - Point out the `instruction` in `agent-prompt.txt` that guides the agent to
      use the tool for financial questions
    - Highlight `tools=[datastore_search_tool]` as the mechanism for RAG
- [agent-prompt.txt] Review the prompt
- [datastore.py] Highlight the `datastore_search_tool` wrapper
    - Show how it simplifies the interface for the agent
    - Takes a single `search_query` string
    - Reads environment variables to pass to the underlying logic
- [datastore.py] Deep dive into the `search` function
    - Explain the `discoveryengine.SearchServiceClient` initialization
    - Show how the `serving_config` path is constructed
    - Discuss the search `request` dictionary:
        - `content_search_spec`: Setting `search_result_mode` to `CHUNKS` is
          critical to get text snippets instead of full PDF downloads
        - `query_expansion_spec`: Enabling `AUTO` expansion helps match synonyms
    - Show how results are extracted from `result.chunk.content`
- Running the code
    - Start `adk web` in the `lesson-08-single-agent-rag` directory
- Demonstration
    - Open the ADK web interface
    - Prompt: What was the largest source of revenue for the past 3 years?
    - Examine calls to `datastore_search_tool`
    - Click on the tool call in the trace to see the input query and the
      returned text chunks
    - Show the final grounded response generated by Gemini
- Conclusion and summary
    - Review how we connected unstructured data in GCS to an agent via Vertex AI
      Agent Builder ("AI Applications")
    - Using ADK tools to bring outside information into the conversation is 
      a powerful way to ground Gemini's responses in our data
